{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_mnist_nn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "or2zMMuOflxp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f0c677cb-2c26-4b6f-9f40-fcc23bf8a1de"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "## create a graph\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "    x = tf.placeholder(dtype=tf.float32,\n",
        "                       shape=(None), name='x')\n",
        "    w = tf.Variable(2.0, name='weight')\n",
        "    b = tf.Variable(0.7, name='bias')\n",
        "\n",
        "    z = w*x + b\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "## create a session and pass in graph g\n",
        "with tf.Session(graph=g) as sess:\n",
        "    ## initialize w and b:\n",
        "    sess.run(init)\n",
        "    ## evaluate z:\n",
        "    for t in [1.0, 0.6, -1.8]:\n",
        "        print('x=%4.1f --> z=%4.1f'%(\n",
        "              t, sess.run(z, feed_dict={x:t})))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x= 1.0 --> z= 2.7\n",
            "x= 0.6 --> z= 1.9\n",
            "x=-1.8 --> z=-2.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jmo-u9Faf7CO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc2ba2ab-4471-41e1-80f0-9165b17c5183"
      },
      "source": [
        "with tf.Session(graph=g) as sess:\n",
        "    sess.run(init)\n",
        "    print(sess.run(z, feed_dict={x:[1., 2., 3.]}))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.7 4.7 6.7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXPLC9ZvgBxO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "641c3406-2b11-4a17-899a-db2b2a18913a"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "    x = tf.placeholder(dtype=tf.float32, \n",
        "                       shape=(None, 2, 3),\n",
        "                       name='input_x')\n",
        "\n",
        "    x2 = tf.reshape(x, shape=(-1, 6),\n",
        "                    name='x2')\n",
        "\n",
        "    ## calculate the sum of each column\n",
        "    xsum = tf.reduce_sum(x2, axis=0, name='col_sum')\n",
        "\n",
        "    ## calculate the mean of each column\n",
        "    xmean = tf.reduce_mean(x2, axis=0, name='col_mean')\n",
        "\n",
        "    \n",
        "with tf.Session(graph=g) as sess:\n",
        "    x_array = np.arange(18).reshape(3, 2, 3)\n",
        "    print('input shape: ', x_array.shape)\n",
        "    print('Reshaped:\\n', \n",
        "          sess.run(x2, feed_dict={x:x_array}))\n",
        "    print('Column Sums:\\n', \n",
        "          sess.run(xsum, feed_dict={x:x_array}))\n",
        "    print('Column Means:\\n', \n",
        "          sess.run(xmean, feed_dict={x:x_array}))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input shape:  (3, 2, 3)\n",
            "Reshaped:\n",
            " [[ 0.  1.  2.  3.  4.  5.]\n",
            " [ 6.  7.  8.  9. 10. 11.]\n",
            " [12. 13. 14. 15. 16. 17.]]\n",
            "Column Sums:\n",
            " [18. 21. 24. 27. 30. 33.]\n",
            "Column Means:\n",
            " [ 6.  7.  8.  9. 10. 11.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLH72B1ggJPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        " \n",
        "X_train = np.arange(10).reshape((10, 1))\n",
        "y_train = np.array([1.0, 1.3, 3.1,\n",
        "                    2.0, 5.0, 6.3, \n",
        "                    6.6, 7.4, 8.0, \n",
        "                    9.0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfNLNCiYgNqJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TfLinreg(object):\n",
        "    \n",
        "    def __init__(self, x_dim, learning_rate=0.01,\n",
        "                 random_seed=None):\n",
        "        self.x_dim = x_dim\n",
        "        self.learning_rate = learning_rate\n",
        "        self.g = tf.Graph()\n",
        "        ## build the model\n",
        "        with self.g.as_default():\n",
        "            ## set graph-level random-seed\n",
        "            tf.set_random_seed(random_seed)\n",
        "            \n",
        "            self.build()\n",
        "            ## create initializer\n",
        "            self.init_op = tf.global_variables_initializer()\n",
        "        \n",
        "    def build(self):\n",
        "        ## define placeholders for inputs\n",
        "        self.X = tf.placeholder(dtype=tf.float32,\n",
        "                                shape=(None, self.x_dim),\n",
        "                                name='x_input')\n",
        "        self.y = tf.placeholder(dtype=tf.float32,\n",
        "                                shape=(None),\n",
        "                                name='y_input')\n",
        "        print(self.X)\n",
        "        print(self.y)\n",
        "        ## define weight matrix and bias vector\n",
        "        w = tf.Variable(tf.zeros(shape=(1)),\n",
        "                        name='weight')\n",
        "        b = tf.Variable(tf.zeros(shape=(1)), \n",
        "                        name=\"bias\")\n",
        "        print(w)\n",
        "        print(b)\n",
        "\n",
        "        self.z_net = tf.squeeze(w*self.X + b,\n",
        "                                name='z_net')\n",
        "        print(self.z_net)\n",
        "        \n",
        "        sqr_errors = tf.square(self.y - self.z_net, \n",
        "                               name='sqr_errors')\n",
        "        print(sqr_errors)\n",
        "        self.mean_cost = tf.reduce_mean(sqr_errors,\n",
        "                                        name='mean_cost')\n",
        "        \n",
        "        optimizer = tf.train.GradientDescentOptimizer(\n",
        "                    learning_rate=self.learning_rate, \n",
        "                    name='GradientDescent')\n",
        "        self.optimizer = optimizer.minimize(self.mean_cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oJu4GTvgRvq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b5c68ecb-a6a7-476b-b193-6da0a51c54b1"
      },
      "source": [
        "lrmodel = TfLinreg(x_dim=X_train.shape[1], learning_rate=0.01)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"x_input:0\", shape=(?, 1), dtype=float32)\n",
            "Tensor(\"y_input:0\", dtype=float32)\n",
            "<tf.Variable 'weight:0' shape=(1,) dtype=float32_ref>\n",
            "<tf.Variable 'bias:0' shape=(1,) dtype=float32_ref>\n",
            "Tensor(\"z_net:0\", dtype=float32)\n",
            "Tensor(\"sqr_errors:0\", dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkCrLxpqgVSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_linreg(sess, model, X_train, y_train, num_epochs=10):\n",
        "    ## initialiaze all variables: W & b\n",
        "    sess.run(model.init_op)\n",
        "    \n",
        "    training_costs = []\n",
        "    for i in range(num_epochs):\n",
        "        _, cost = sess.run([model.optimizer, model.mean_cost], \n",
        "                           feed_dict={model.X:X_train, \n",
        "                                      model.y:y_train})\n",
        "        training_costs.append(cost)\n",
        "        \n",
        "    return training_costs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVLvpSSNgYPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.Session(graph=lrmodel.g)\n",
        "training_costs = train_linreg(sess, lrmodel, X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tur3nPVrgb7S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "8a4d534b-cc8c-4917-e8f0-288b8d339113"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(1,len(training_costs) + 1), training_costs)\n",
        "plt.tight_layout()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Cost')\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbYAAAEmCAYAAAAOb7UzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5ULNId6giQL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_linreg(sess, model, X_test):\n",
        "    y_pred = sess.run(model.z_net, \n",
        "                      feed_dict={model.X:X_test})\n",
        "    return y_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOQ6nq0Ygmms",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "e593c744-b87a-4c4e-a3a4-fb2582b3ac42"
      },
      "source": [
        "plt.scatter(X_train, y_train,\n",
        "            marker='s', s=50,\n",
        "            label='Training Data')\n",
        "plt.plot(range(X_train.shape[0]), \n",
        "         predict_linreg(sess, lrmodel, X_train),\n",
        "         color='gray', marker='o', \n",
        "         markersize=10, linewidth=1,\n",
        "         label='LinReg Model')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3dLLvKLgzzQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "74057447-58fd-4385-dd60-cf6f0a8dc370"
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('C:/Users/Svitlana', one_hot=True)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0808 18:43:10.547390 139726750414720 deprecation.py:323] From <ipython-input-17-9a82ca98995c>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "W0808 18:43:10.549406 139726750414720 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "W0808 18:43:10.554818 139726750414720 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "W0808 18:43:10.649180 139726750414720 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting C:/Users/Svitlana/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0808 18:43:10.944305 139726750414720 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "W0808 18:43:10.947067 139726750414720 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "W0808 18:43:11.041656 139726750414720 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting C:/Users/Svitlana/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting C:/Users/Svitlana/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting C:/Users/Svitlana/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J72MCbgDix5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "eb563788-036f-46d2-c896-57f1b8e4a390"
      },
      "source": [
        "image_size = 28\n",
        "labels_size = 10\n",
        "learning_rate = 0.05\n",
        "steps_number = 1000\n",
        "batch_size = 100\n",
        "\n",
        "training_data = tf.placeholder(tf.float32, [None, image_size*image_size])\n",
        "labels = tf.placeholder(tf.float32, [None, labels_size])\n",
        "\n",
        "# Variables to be tuned\n",
        "W = tf.Variable(tf.truncated_normal([image_size*image_size, labels_size], stddev=0.1))\n",
        "b = tf.Variable(tf.constant(0.1, shape=[labels_size]))\n",
        "\n",
        "# Build the network (only output layer)\n",
        "output = tf.matmul(training_data, W) + b\n",
        "\n",
        "# Define the loss function\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=output))\n",
        "\n",
        "# Training step\n",
        "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
        "\n",
        "# Accuracy calculation\n",
        "correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(labels, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "# Run the training\n",
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "\n",
        "for i in range(steps_number):\n",
        "  # Get the next batch\n",
        "  input_batch, labels_batch = mnist.train.next_batch(batch_size)\n",
        "  feed_dict = {training_data: input_batch, labels: labels_batch}\n",
        "\n",
        "  # Run the training step\n",
        "  train_step.run(feed_dict=feed_dict)\n",
        "\n",
        "  # Print the accuracy progress on the batch every 100 steps\n",
        "  if i%100 == 0:\n",
        "    train_accuracy = accuracy.eval(feed_dict=feed_dict)\n",
        "    print(\"Step %d, training batch accuracy %g %%\"%(i, train_accuracy*100))\n",
        "    \n",
        "# Evaluate on the test set\n",
        "test_accuracy = accuracy.eval(feed_dict={training_data: mnist.test.images, labels: mnist.test.labels})\n",
        "print(\"Test accuracy: %g %%\"%(test_accuracy*100))    \n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0808 18:49:37.795450 139726750414720 deprecation.py:323] From <ipython-input-21-42fedaaef333>:18: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 0, training batch accuracy 4 %\n",
            "Step 100, training batch accuracy 85 %\n",
            "Step 200, training batch accuracy 85 %\n",
            "Step 300, training batch accuracy 89 %\n",
            "Step 400, training batch accuracy 83 %\n",
            "Step 500, training batch accuracy 92 %\n",
            "Step 600, training batch accuracy 86 %\n",
            "Step 700, training batch accuracy 94 %\n",
            "Step 800, training batch accuracy 92 %\n",
            "Step 900, training batch accuracy 92 %\n",
            "Test accuracy: 90.01 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6-0f1twkh7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "573ddfbd-4a5d-442b-e730-3cc58a00555f"
      },
      "source": [
        "n_features = mnist.train.images.shape[1]\n",
        "n_classes = 10\n",
        "random_seed = 123\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "    tf.set_random_seed(random_seed)\n",
        "    tf_x = tf.placeholder(dtype=tf.float32,\n",
        "                       shape=(None, n_features),\n",
        "                       name='tf_x')\n",
        "\n",
        "    tf_y = tf.placeholder(dtype=tf.int32, \n",
        "                        shape=None, name='tf_y')\n",
        "    y_onehot = tf.one_hot(indices=tf_y, depth=n_classes)\n",
        "\n",
        "    h1 = tf.layers.dense(inputs=tf_x, units=50,\n",
        "                         activation=tf.tanh,\n",
        "                         name='layer1')\n",
        "\n",
        "    h2 = tf.layers.dense(inputs=h1, units=50,\n",
        "                         activation=tf.tanh,\n",
        "                         name='layer2')\n",
        "\n",
        "    logits = tf.layers.dense(inputs=h2, \n",
        "                             units=10,\n",
        "                             activation=None,\n",
        "                             name='layer3')\n",
        "\n",
        "    predictions = {\n",
        "        'classes' : tf.argmax(logits, axis=1, \n",
        "                              name='predicted_classes'),\n",
        "        'probabilities' : tf.nn.softmax(logits, \n",
        "                              name='softmax_tensor')\n",
        "    }"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0808 18:51:49.821518 139726750414720 deprecation.py:323] From <ipython-input-22-baa7236c528e>:19: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "W0808 18:51:49.829909 139726750414720 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qn9HX-6akuuP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "42aeb905-1643-4343-dadc-9c5d9a6823f0"
      },
      "source": [
        "with g.as_default():\n",
        "    cost = tf.losses.softmax_cross_entropy(\n",
        "            onehot_labels=y_onehot, logits=logits)\n",
        "\n",
        "    optimizer = tf.train.GradientDescentOptimizer(\n",
        "            learning_rate=0.001)\n",
        "\n",
        "    train_op = optimizer.minimize(loss=cost)\n",
        "\n",
        "    init_op = tf.global_variables_initializer()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0808 18:52:14.622904 139726750414720 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJjgN8sCkz7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_batch_generator(X, y, batch_size=128, shuffle=False):\n",
        "    X_copy = np.array(X)\n",
        "    y_copy = np.array(y)\n",
        "    \n",
        "    if shuffle:\n",
        "        data = np.column_stack((X_copy, y_copy))\n",
        "        np.random.shuffle(data)\n",
        "        X_copy = data[:, :-1]\n",
        "        y_copy = data[:, -1].astype(int)\n",
        "    \n",
        "    for i in range(0, X.shape[0], batch_size):\n",
        "        yield (X_copy[i:i+batch_size, :], y_copy[i:i+batch_size])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X37jT2Dsk3K6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "73ab2e5e-3c2d-46a3-fe6b-68caf96bacf0"
      },
      "source": [
        "lbl = np.argmax(mnist.train.labels, axis=1)\n",
        "## create a session to launch the graph\n",
        "sess =  tf.Session(graph=g)\n",
        "## run the variable initialization operator\n",
        "sess.run(init_op)\n",
        "\n",
        "## 50 epochs of training:\n",
        "training_costs = []\n",
        "for epoch in range(50):\n",
        "    training_loss = []\n",
        "    batch_generator = create_batch_generator(\n",
        "            mnist.train.images, lbl, \n",
        "            batch_size=64)\n",
        "    for batch_X, batch_y in batch_generator:\n",
        "        ## prepare a dict to feed data to our network:\n",
        "        feed = {tf_x:batch_X, tf_y:batch_y}\n",
        "        _, batch_cost = sess.run([train_op, cost], feed_dict=feed)\n",
        "        training_costs.append(batch_cost)\n",
        "    print(' -- Epoch %2d  '\n",
        "          'Avg. Training Loss: %.4f' % (\n",
        "              epoch+1, np.mean(training_costs)\n",
        "    ))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " -- Epoch  1  Avg. Training Loss: 1.9882\n",
            " -- Epoch  2  Avg. Training Loss: 1.7010\n",
            " -- Epoch  3  Avg. Training Loss: 1.5058\n",
            " -- Epoch  4  Avg. Training Loss: 1.3647\n",
            " -- Epoch  5  Avg. Training Loss: 1.2569\n",
            " -- Epoch  6  Avg. Training Loss: 1.1712\n",
            " -- Epoch  7  Avg. Training Loss: 1.1011\n",
            " -- Epoch  8  Avg. Training Loss: 1.0423\n",
            " -- Epoch  9  Avg. Training Loss: 0.9922\n",
            " -- Epoch 10  Avg. Training Loss: 0.9489\n",
            " -- Epoch 11  Avg. Training Loss: 0.9110\n",
            " -- Epoch 12  Avg. Training Loss: 0.8775\n",
            " -- Epoch 13  Avg. Training Loss: 0.8476\n",
            " -- Epoch 14  Avg. Training Loss: 0.8208\n",
            " -- Epoch 15  Avg. Training Loss: 0.7965\n",
            " -- Epoch 16  Avg. Training Loss: 0.7745\n",
            " -- Epoch 17  Avg. Training Loss: 0.7543\n",
            " -- Epoch 18  Avg. Training Loss: 0.7358\n",
            " -- Epoch 19  Avg. Training Loss: 0.7187\n",
            " -- Epoch 20  Avg. Training Loss: 0.7029\n",
            " -- Epoch 21  Avg. Training Loss: 0.6882\n",
            " -- Epoch 22  Avg. Training Loss: 0.6745\n",
            " -- Epoch 23  Avg. Training Loss: 0.6617\n",
            " -- Epoch 24  Avg. Training Loss: 0.6498\n",
            " -- Epoch 25  Avg. Training Loss: 0.6385\n",
            " -- Epoch 26  Avg. Training Loss: 0.6279\n",
            " -- Epoch 27  Avg. Training Loss: 0.6179\n",
            " -- Epoch 28  Avg. Training Loss: 0.6084\n",
            " -- Epoch 29  Avg. Training Loss: 0.5994\n",
            " -- Epoch 30  Avg. Training Loss: 0.5909\n",
            " -- Epoch 31  Avg. Training Loss: 0.5828\n",
            " -- Epoch 32  Avg. Training Loss: 0.5751\n",
            " -- Epoch 33  Avg. Training Loss: 0.5678\n",
            " -- Epoch 34  Avg. Training Loss: 0.5607\n",
            " -- Epoch 35  Avg. Training Loss: 0.5540\n",
            " -- Epoch 36  Avg. Training Loss: 0.5476\n",
            " -- Epoch 37  Avg. Training Loss: 0.5414\n",
            " -- Epoch 38  Avg. Training Loss: 0.5355\n",
            " -- Epoch 39  Avg. Training Loss: 0.5298\n",
            " -- Epoch 40  Avg. Training Loss: 0.5243\n",
            " -- Epoch 41  Avg. Training Loss: 0.5190\n",
            " -- Epoch 42  Avg. Training Loss: 0.5139\n",
            " -- Epoch 43  Avg. Training Loss: 0.5090\n",
            " -- Epoch 44  Avg. Training Loss: 0.5043\n",
            " -- Epoch 45  Avg. Training Loss: 0.4997\n",
            " -- Epoch 46  Avg. Training Loss: 0.4952\n",
            " -- Epoch 47  Avg. Training Loss: 0.4909\n",
            " -- Epoch 48  Avg. Training Loss: 0.4868\n",
            " -- Epoch 49  Avg. Training Loss: 0.4828\n",
            " -- Epoch 50  Avg. Training Loss: 0.4788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT8S_1TrmGGD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "933a4677-bffe-477a-c02e-da7e9408a51b"
      },
      "source": [
        "## do prediction on the test set:\n",
        "feed = {tf_x : mnist.test.images}\n",
        "y_pred = sess.run(predictions['classes'], \n",
        "                  feed_dict=feed)\n",
        " \n",
        "print('Test Accuracy: %.2f%%' % (\n",
        "      100*np.sum(y_pred == np.argmax(mnist.test.labels, axis=1))/np.argmax(mnist.test.labels, axis=1).shape[0]))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 92.24%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}